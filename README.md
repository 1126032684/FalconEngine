# 用GO语言实现一个简单的搜索引擎

项目地址是：[https://github.com/wyh267/FalconEngine](https://github.com/wyh267/FalconEngine)

## 注意：：：：：项目完全重构，代码基本完成，README稍后完成全部更新

对搜索引擎感兴趣的可以去看看[这本书](http://www.amazon.cn/%E8%BF%99%E5%B0%B1%E6%98%AF%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3-%E5%BC%A0%E4%BF%8A%E6%9E%97/dp/B006J9MSD8)，比较浅并且也比较完整的介绍了一个搜索引擎的全部机能。

## 主要功能点，更新列表
 - 类似于数据库的表一样按字段进行存储
 - 支持倒排索引字段，正排索引字段，仅仅储存不进行检索的字段
 - 倒排索引支持
    - 完全匹配的字符串（类似ID,ISBN等需要完全匹配的属性）
    - 分词类型 （全文索引）
    - 根据特殊标志符进行切分的模式
 - 正排索引支持
    - 数字索引（暂时只支持整数，需要自己将其他数转化成整数）
    - 日期索引（目前支持`2005-01-02 00:02:03`和`2005-01-02`两种格式）
    - 不进行检索字段，只存储详细信息
 - 实时搜索引擎，索引器和检索器就是同一个服务，通过json方式push数据进引擎，引擎自行就行存储，不需要先进行全量索引建立
 - 支持搜索，过滤，汇总，统计四种查询
 - 策略引擎部分可以自己实现接口进行扩展
 - 无配置文件，只需要在启动的时候指定端口
 - 使用MMAP方式进行数据存储和读取
 - 使用B+树进行字典和key的存储
 - 实时索引，随时进行索引更新
 - 默认使用文本相关性进行排序
 - 性能测试报告稍后提交

  
## TODO列表
  - 增加选项，可以一次性将所有数据加载进内存
  - 索引分片
  - 分布式部署，保存多个副本
  - 集群化搜索引擎

## 性能测试
  - 进行中

## 使用方法
### 依赖以下几个库
- [github.com/apsdehal/go-logger](https://github.com/apsdehal/go-logger) log文件
- [github.com/huichen/sego](https://github.com/huichen/sego) 分词器，作者[主页](https://github.com/huichen)非常感谢他的分析器，他主页上也有个搜索引擎，没看具体实现，大家感兴趣可以去看看。

### 编译
- 直接运行`install.sh`

### 运行
- 从[github.com/huichen/sego](https://github.com/huichen/sego)获取分词的字典文件,存入当前目录的'data'下
- 新建index文件夹
- 运行
> bin/FalconEngine  【默认端口9990】

## 文件结构说明


## 默认引擎基本操作API说明

整个系统分为三部分
    - 一部分是`FalconIndex`目录下，这部分是索引部分，对外只有一个Index类和相应的方法，提供索引的基本操作
    - 一部分是引擎部分，在`FalconEngine`文件夹中，此文件夹中已经实现了一个默认引擎，自己的引擎需要实现`utils.go`下面的引擎方法
    - 一部分是网络部分，在`FalconService`文件夹中，此文件夹已经实现了一个默认的HTTP服务
引擎接口：


```
    // Engine 引擎接口，自己实现的引擎必须实现以下接口
    type Engine interface {
        Search(method string, parms map[string]string, body []byte) (string, error)
        CreateIndex(method string, parms map[string]string, body []byte) error
        UpdateDocument(method string, parms map[string]string, body []byte) (string, error)
        DeleteDocument(method string, parms map[string]string, body []byte) (string, error)
        LoadData(method string, parms map[string]string, body []byte) (string, error)
    }
```

默认引擎使用方法

### 新建索引



### 增加索引字段

### 删除索引字段

### 从文件进行索引更新

### 直接更新索引

### 删除索引

### 查询接口


## 代码架构说明

### 模块图

## 部署说明

## 基本概念

以下几个概念需要理解，如果完全不了解的话，还需要自己稍微百度一下：`倒排索引`，`正排文件`，`Detail文件`，`全量索引`，`增量索引`，`哈希函数`，`DocId`


## 基础数据结构

搜索引擎首先并不神秘，基础的数据结构就那么几个，定了以后后面就是在上面添砖加瓦了。

假如有下面五个文档需要进行搜索

| 文档编号 | 内容 |
|---------|------|
| 1 | 你好，搜索引擎 |
|2 | 搜索引擎有一条数据 |
|3 | 你好，有一条测试数据 |

### 倒排索引

倒排索引是搜索引擎基础中的基础，主要的检索都是从倒排索引开始的，所以，首先，设计一个倒排索引的数据结构是所有搜索引擎的基础。

搜索引擎的基础是DocId，也就是文档ID，DocId是唯一的并且是连续的，而倒排索引就是一组DocId链表，每个链表对应一个关键词。

上面的文档建立号倒排索引的基础结构如下图

|关键词 | 文档编号 |
| ------|--------|
| 你好| 1，3|
|搜索引擎 | 1，2   |
|数据 | 2，3 |
|有一条 | 2，3   |
| 测试 |  3  |

所以，当我们检索`数据`这个词的时候能迅速知道在文档**2**和**3**有这条数据，就能进行检索了。

是不是很简单，关键问题是检索`数据`的时候，如何能迅速定位到第三行数据，这里就用到`哈希表`了，所以，一个完整的倒排包括两部分，一部分是上面的这个表，第二个是一个哈希表，通过这个哈希表能知道`数据`这个词的下标为`3`，从而找到`2,3`这两个文档。

`哈希表`的具体实现就不详细展开了，`哈希表`有很多种实现方式，并且哈希函数也有很多种实现方式，总之，对于一个关键词的定位
- 首先，通过计算这个关键词的hash，得到它的下标
- 然后，查找倒排索引的下标，得到文档ID的链表

在代码的`InvertIndex.go`中是倒排索引的数据结构，`StringIndexDic.go`是关键词的哈希表，这两个文件产生的数据都会序列化成`json`文件存储下来。

### 正排索引

正排索引相对倒排就简单多了，实际上就是一个字典文件，`key`是DocId，`value`是这个DocId对应的内容，主要用来做结果集的过滤，所谓`倒排检索，正排过滤`，什么场景需要这样的东西呢？下面的场景你肯定经历过。

你在一个某东的网站搜索`运动鞋`，肯定出来一堆鞋子，但是你只想看`nike`的鞋子，这时候你可以再运动鞋后面加上Nike，搜索`nike运动鞋`，但是结果不一定准，因为并不是每个nike的鞋子的标题上都会写上nike，这时候就需要用到正排了，他会把nike鞋子给你过滤出来。

正排索引就是一个数组，数组的下标就是`DocId`，文件中的`NumberProfile.go`和`TextProfile.go`是具体的实现文件


## 增量更新

## 数据检索

数据检索分成以下几个步骤

- 根据关键词从倒排索引中获取DocId链，有多个关键词的时候求交集
- 通过`BitMap`过滤掉已经删除的DocId
- 最后得到的DocId按照正排文件的条件进行过滤操作，获取最终的DocId链
- 通过DocId反查出文档的真实ID，并通过Redis获取文档的详细信息用于显示



